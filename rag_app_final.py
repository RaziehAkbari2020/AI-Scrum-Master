# -*- coding: utf-8 -*-
"""RAG_App_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SQ8EPM95RFb9NkE-l3W-8LfJ_-mWPeyy
"""

# -*- coding: utf-8 -*-
"""RAG_App.py — Retrieval-Augmented Generation App with Persistent Memory"""

# ------------------ Imports ------------------
import os, json, uuid
from pathlib import Path


import streamlit as st

if not st.session_state.get("_pg_cfg_set"):
    st.set_page_config(page_title="As A Agile Project Manager Chat with your data", page_icon="💬")
    st.session_state["_pg_cfg_set"] = True
st.image("Logo_UPC_pillars.jpg", width=120)

st.title("As an Agile Project Manager, chat with your data")


# from langchain.schema import Document
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chat_models import init_chat_model
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.tools import tool
from langchain_core.messages import SystemMessage
from langgraph.graph import MessagesState, StateGraph, END
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.sqlite import SqliteSaver  # 👈 persistent memory

# ------------------ Page ------------------
# st.set_page_config(page_title="As A Scrum Master Chat with your data", page_icon="💬")
# st.title("As A Scrum Master Chat with your data")

# ------------------ API keys ------------------
# ⚠️ فقط برای تست محلی: قبل از انتشار، مقدار هاردکد را حذف کن یا secrets.toml بساز.
try:
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
except Exception:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

if not (OPENAI_API_KEY and (OPENAI_API_KEY.startswith("sk-") or OPENAI_API_KEY.startswith("sk-proj-"))):
    st.error("OPENAI_API_KEY در Secrets تنظیم نشده یا معتبر نیست.")
    st.stop()

# ------------------ Upload JSONL ------------------
up = st.file_uploader("Upload your data (each line: {page_content, metadata})", type=["jsonl"])
if not up:
    st.info("Please upload the file documents.jsonl.")
    st.stop()

# اگر فایل جدیدی (اسم/سایز متفاوت) آپلود شد، ایندکس قبلی را پاک کن
upload_sig = (up.name, getattr(up, "size", None))
if st.session_state.get("last_upload_sig") != upload_sig:
    st.session_state.pop("vector_store", None)
    st.session_state["last_upload_sig"] = upload_sig

# خواندن اسناد
documents = []
for line in up:
    obj = json.loads(line.decode("utf-8"))
    documents.append(Document(page_content=obj["page_content"], metadata=obj.get("metadata", {})))


# ------------------ Chunking ------------------
text_splitter = RecursiveCharacterTextSplitter(
    separators=["\n\n", "\n", ".", " "],
    chunk_size=1000,
    chunk_overlap=100,
)
chunks = text_splitter.split_documents(documents)
st.caption(f"🔹 Total chunks created: {len(chunks)}")

# ------------------ Embeddings & Vector Store (FAISS) ------------------
embeddings = OpenAIEmbeddings(model="text-embedding-3-large", api_key=OPENAI_API_KEY)

# ایندکس را فقط یک‌بار بساز و در سشن نگه دار (جلوی ری‌ران‌های Streamlit)
if "vector_store" not in st.session_state:
    st.session_state["vector_store"] = FAISS.from_documents(chunks, embeddings)
vector_store = st.session_state["vector_store"]

# ------------------ Retrieve tool ------------------
@tool(response_format="content_and_artifact")
def retrieve(query: str):
    """Retrieve user stories related to a query."""
    retrieved_docs = vector_store.similarity_search(query, k=5)
    serialized = "\n\n".join(
        (
            f"🔹 User Story ID: {doc.metadata.get('us_id')}\n"
            f"📄 Content:\n{doc.page_content}"
        )
        for doc in retrieved_docs
    )
    return serialized, retrieved_docs

# ------------------ LLM ------------------
llm = init_chat_model("gpt-4o-mini", model_provider="openai", api_key=OPENAI_API_KEY)

# ------------------ Steps ------------------
def query_or_respond(state: MessagesState):
    llm_with_tools = llm.bind_tools([retrieve])
    response = llm_with_tools.invoke(state["messages"])
    return {"messages": [response]}

tools = ToolNode([retrieve])

def generate(state: MessagesState):
    # جمع‌آوری ToolMessages اخیر
    recent_tool_messages = []
    for message in reversed(state["messages"]):
        if message.type == "tool":
            recent_tool_messages.append(message)
        else:
            break
    tool_messages = recent_tool_messages[::-1]

    docs_content = "\n\n".join(doc.content for doc in tool_messages)
    system_message_content = (
        "You are a professional Scrum Master specializing in Agile Project Management in the field of Software Engineering.\n\n"
        "When a user asks a question:\n"
        "- First, explain your reasoning step-by-step before answering.\n"
        "- Specify which fields (e.g., user story, description, priority, acceptance criteria, tasks, effort) you will use to answer the question, and why you chose them.\n"
        "- Justify your reasoning as an Agile expert.\n"
        "- Provide your final answer immediately after your reasoning.\n\n"
        "Here is the retrieved context:\n"
        f"{docs_content}"
    )
    conversation_messages = [
        message for message in state["messages"]
        if message.type in ("human", "system") or (message.type == "ai" and not message.tool_calls)
    ]
    prompt = [SystemMessage(system_message_content)] + conversation_messages
    response = llm.invoke(prompt)
    return {"messages": [response]}

# ------------------ Graph + Persistent Checkpointer ------------------
# graph_builder = StateGraph(MessagesState)
# graph_builder.add_node("router", query_or_respond)
# graph_builder.add_node("tools", tools)
# graph_builder.add_node("generate", generate)
# graph_builder.set_entry_point("router")
# graph_builder.add_edge("router", "tools")
# graph_builder.add_edge("tools", "generate")
# graph_builder.add_edge("generate", END)

# # ✅ حافظهٔ پایدار روی دیسک
# saver = SqliteSaver.from_conn_string("rag_state.sqlite")
# graph = graph_builder.compile(checkpointer=saver)



# ------------------ Graph + Persistent Checkpointer ------------------
graph_builder = StateGraph(MessagesState)
graph_builder.add_node("router", query_or_respond)
graph_builder.add_node("tools", tools)
graph_builder.add_node("generate", generate)
graph_builder.set_entry_point("router")
graph_builder.add_edge("router", "tools")
graph_builder.add_edge("tools", "generate")
graph_builder.add_edge("generate", END)


# ------------------ Streamlit Chat UI ------------------
# if "messages" not in st.session_state:
#     st.session_state.messages = []  # تاریخچه UI

# # thread_id پایدار (برای LangGraph)
# if "thread_id" not in st.session_state:
#     st.session_state.thread_id = str(uuid.uuid4())
# config = {"configurable": {"thread_id": st.session_state.thread_id}}

# # نمایش تاریخچه
# for m in st.session_state.messages:
#     with st.chat_message(m["role"]):
#         st.markdown(m["content"])

# user_input = st.chat_input("Ask your Question")
# if user_input:
#     st.session_state.messages.append({"role": "user", "content": user_input})
#     with st.chat_message("user"):
#         st.markdown(user_input)

#     # 👈 کل تاریخچه را به گراف بده، نه فقط آخرین پیام
#     history = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]

#     ai_text = None
#     placeholder = st.chat_message("assistant").empty()
#     for step in graph.stream(
#         {"messages": history},
#         stream_mode="values",
#         config=config,
#     ):
#         msgs = step.get("messages", [])
#         if msgs:
#             last = msgs[-1]
#             if getattr(last, "type", None) == "ai" and getattr(last, "content", ""):
#                 ai_text = last.content
#                 placeholder.markdown(ai_text)

#     if ai_text:
#         st.session_state.messages.append({"role": "assistant", "content": ai_text})

# st.divider()
# if st.button("🗑️ Clear chat"):
#     st.session_state.messages = []
#     # thread_id را هم ریست نکن تا state گراف حفظ شود؛ اگر می‌خواهی، این خط را هم آنکامنت کن:
#     # st.session_state.thread_id = str(uuid.uuid4())
#     st.experimental_rerun()





with SqliteSaver.from_conn_string("rag_state.sqlite") as saver:
    graph = graph_builder.compile(checkpointer=saver)

    # ------------------ Streamlit Chat UI ------------------
    if "messages" not in st.session_state:
        st.session_state.messages = []

    if "thread_id" not in st.session_state:
        st.session_state.thread_id = str(uuid.uuid4())
    config = {"configurable": {"thread_id": st.session_state.thread_id}}

    for m in st.session_state.messages:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    user_input = st.chat_input("Ask your Question")
    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        history = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]

        ai_text = None
        placeholder = st.chat_message("assistant").empty()
        for step in graph.stream(
            {"messages": history},
            stream_mode="values",
            config=config,
        ):
            msgs = step.get("messages", [])
            if msgs:
                last = msgs[-1]
                if getattr(last, "type", None) == "ai" and getattr(last, "content", ""):
                    ai_text = last.content
                    placeholder.markdown(ai_text)

        if ai_text:
            st.session_state.messages.append({"role": "assistant", "content": ai_text})

    st.divider()
    if st.button("🗑️ Clear chat"):
        st.session_state.messages = []
        st.experimental_rerun()
